{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Origem dos dados: https://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\n",
    "|\n",
    "| 48 continuous real [0,100] attributes of type word_freq_WORD \n",
    "| = percentage of words in the e-mail that match WORD,\n",
    "| i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
    "| total number of words in e-mail.  A \"word\" in this case is any \n",
    "| string of alphanumeric characters bounded by non-alphanumeric \n",
    "| characters or end-of-string.\n",
    "|\n",
    "| 6 continuous real [0,100] attributes of type char_freq_CHAR\n",
    "| = percentage of characters in the e-mail that match CHAR,\n",
    "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
    "|\n",
    "| 1 continuous real [1,...] attribute of type capital_run_length_average\n",
    "| = average length of uninterrupted sequences of capital letters\n",
    "|\n",
    "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
    "| = length of longest uninterrupted sequence of capital letters\n",
    "|\n",
    "| 1 continuous integer [1,...] attribute of type capital_run_length_total\n",
    "| = sum of length of uninterrupted sequences of capital letters\n",
    "| = total number of capital letters in the e-mail\n",
    "|\n",
    "| 1 nominal {0,1} class attribute of type spam\n",
    "| = denotes whether the e-mail was considered spam (1) or not (0), \n",
    "| i.e. unsolicited commercial e-mail.  \n",
    "|\n",
    "| For more information, see file 'spambase.DOCUMENTATION' at the\n",
    "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'C:\\\\Users\\\\Lenovo\\\\Documents\\\\BigData\\\\machine learning algorithms'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downloading the datasets:\n",
    "import requests as re\n",
    "resp = re.get('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names')\n",
    "with open('data/spambase.names', 'w') as f:\n",
    "    f.write(resp.text)\n",
    "    \n",
    "\n",
    "data_header = ['word_freq_make',\n",
    "    'word_freq_address',\n",
    "    'word_freq_all',\n",
    "    'word_freq_3d',\n",
    "    'word_freq_our',\n",
    "    'word_freq_over',\n",
    "    'word_freq_remove',\n",
    "    'word_freq_internet',\n",
    "    'word_freq_order',\n",
    "    'word_freq_mail',\n",
    "    'word_freq_receive',\n",
    "    'word_freq_will',\n",
    "    'word_freq_people',\n",
    "    'word_freq_report',\n",
    "    'word_freq_addresses',\n",
    "    'word_freq_free',\n",
    "    'word_freq_business',\n",
    "    'word_freq_email',\n",
    "    'word_freq_you',\n",
    "    'word_freq_credit',\n",
    "    'word_freq_your',\n",
    "    'word_freq_font',\n",
    "    'word_freq_000',\n",
    "    'word_freq_money',\n",
    "    'word_freq_hp',\n",
    "    'word_freq_hpl',\n",
    "    'word_freq_george',\n",
    "    'word_freq_650',\n",
    "    'word_freq_lab',\n",
    "    'word_freq_labs',\n",
    "    'word_freq_telnet',\n",
    "    'word_freq_857',\n",
    "    'word_freq_data',\n",
    "    'word_freq_415',\n",
    "    'word_freq_85',\n",
    "    'word_freq_technology',\n",
    "    'word_freq_1999',\n",
    "    'word_freq_parts',\n",
    "    'word_freq_pm',\n",
    "    'word_freq_direct',\n",
    "    'word_freq_cs',\n",
    "    'word_freq_meeting',\n",
    "    'word_freq_original',\n",
    "    'word_freq_project',\n",
    "    'word_freq_re',\n",
    "    'word_freq_edu',\n",
    "    'word_freq_table',\n",
    "    'word_freq_conference',\n",
    "    'char_freq_;',\n",
    "    'char_freq_(',\n",
    "    'char_freq_[',\n",
    "    'char_freq_!',\n",
    "    'char_freq_$',\n",
    "    'char_freq_#',\n",
    "    'capital_run_length_average',\n",
    "    'capital_run_length_longest',\n",
    "    'capital_run_length_total',\n",
    "    'spam']\n",
    "    \n",
    "resp = re.get('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data')\n",
    "with open('data/spambase.data', 'w') as f:\n",
    "    f.write(','.join(data_header) + '\\n')\n",
    "    f.write(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-notebook')\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 59 columns):\n",
      "id                            4601 non-null int64\n",
      "word_freq_make                4601 non-null float64\n",
      "word_freq_address             4601 non-null float64\n",
      "word_freq_all                 4601 non-null float64\n",
      "word_freq_3d                  4601 non-null float64\n",
      "word_freq_our                 4601 non-null float64\n",
      "word_freq_over                4601 non-null float64\n",
      "word_freq_remove              4601 non-null float64\n",
      "word_freq_internet            4601 non-null float64\n",
      "word_freq_order               4601 non-null float64\n",
      "word_freq_mail                4601 non-null float64\n",
      "word_freq_receive             4601 non-null float64\n",
      "word_freq_will                4601 non-null float64\n",
      "word_freq_people              4601 non-null float64\n",
      "word_freq_report              4601 non-null float64\n",
      "word_freq_addresses           4601 non-null float64\n",
      "word_freq_free                4601 non-null float64\n",
      "word_freq_business            4601 non-null float64\n",
      "word_freq_email               4601 non-null float64\n",
      "word_freq_you                 4601 non-null float64\n",
      "word_freq_credit              4601 non-null float64\n",
      "word_freq_your                4601 non-null float64\n",
      "word_freq_font                4601 non-null float64\n",
      "word_freq_000                 4601 non-null float64\n",
      "word_freq_money               4601 non-null float64\n",
      "word_freq_hp                  4601 non-null float64\n",
      "word_freq_hpl                 4601 non-null float64\n",
      "word_freq_george              4601 non-null float64\n",
      "word_freq_650                 4601 non-null float64\n",
      "word_freq_lab                 4601 non-null float64\n",
      "word_freq_labs                4601 non-null float64\n",
      "word_freq_telnet              4601 non-null float64\n",
      "word_freq_857                 4601 non-null float64\n",
      "word_freq_data                4601 non-null float64\n",
      "word_freq_415                 4601 non-null float64\n",
      "word_freq_85                  4601 non-null float64\n",
      "word_freq_technology          4601 non-null float64\n",
      "word_freq_1999                4601 non-null float64\n",
      "word_freq_parts               4601 non-null float64\n",
      "word_freq_pm                  4601 non-null float64\n",
      "word_freq_direct              4601 non-null float64\n",
      "word_freq_cs                  4601 non-null float64\n",
      "word_freq_meeting             4601 non-null float64\n",
      "word_freq_original            4601 non-null float64\n",
      "word_freq_project             4601 non-null float64\n",
      "word_freq_re                  4601 non-null float64\n",
      "word_freq_edu                 4601 non-null float64\n",
      "word_freq_table               4601 non-null float64\n",
      "word_freq_conference          4601 non-null float64\n",
      "char_freq_;                   4601 non-null float64\n",
      "char_freq_(                   4601 non-null float64\n",
      "char_freq_[                   4601 non-null float64\n",
      "char_freq_!                   4601 non-null float64\n",
      "char_freq_$                   4601 non-null float64\n",
      "char_freq_#                   4601 non-null float64\n",
      "capital_run_length_average    4601 non-null float64\n",
      "capital_run_length_longest    4601 non-null int64\n",
      "capital_run_length_total      4601 non-null int64\n",
      "spam                          4601 non-null int64\n",
      "dtypes: float64(55), int64(4)\n",
      "memory usage: 2.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0   0            0.00               0.64           0.64           0.0   \n",
       "1   1            0.21               0.28           0.50           0.0   \n",
       "2   2            0.06               0.00           0.71           0.0   \n",
       "3   3            0.00               0.00           0.00           0.0   \n",
       "4   4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  ...   char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "0             0.00  ...          0.00        0.000          0.0        0.778   \n",
       "1             0.00  ...          0.00        0.132          0.0        0.372   \n",
       "2             0.64  ...          0.01        0.143          0.0        0.276   \n",
       "3             0.31  ...          0.00        0.137          0.0        0.137   \n",
       "4             0.31  ...          0.00        0.135          0.0        0.135   \n",
       "\n",
       "   char_freq_$  char_freq_#  capital_run_length_average  \\\n",
       "0        0.000        0.000                       3.756   \n",
       "1        0.180        0.048                       5.114   \n",
       "2        0.184        0.010                       9.821   \n",
       "3        0.000        0.000                       3.537   \n",
       "4        0.000        0.000                       3.537   \n",
       "\n",
       "   capital_run_length_longest  capital_run_length_total  spam  \n",
       "0                          61                       278     1  \n",
       "1                         101                      1028     1  \n",
       "2                         485                      2259     1  \n",
       "3                          40                       191     1  \n",
       "4                          40                       191     1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2300.000000</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1328.338624</td>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3450.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  word_freq_make  word_freq_address  word_freq_all  \\\n",
       "count  4601.000000     4601.000000        4601.000000    4601.000000   \n",
       "mean   2300.000000        0.104553           0.213015       0.280656   \n",
       "std    1328.338624        0.305358           1.290575       0.504143   \n",
       "min       0.000000        0.000000           0.000000       0.000000   \n",
       "25%    1150.000000        0.000000           0.000000       0.000000   \n",
       "50%    2300.000000        0.000000           0.000000       0.000000   \n",
       "75%    3450.000000        0.000000           0.000000       0.420000   \n",
       "max    4600.000000        4.540000          14.280000       5.100000   \n",
       "\n",
       "       word_freq_3d  word_freq_our  word_freq_over  word_freq_remove  \\\n",
       "count   4601.000000    4601.000000     4601.000000       4601.000000   \n",
       "mean       0.065425       0.312223        0.095901          0.114208   \n",
       "std        1.395151       0.672513        0.273824          0.391441   \n",
       "min        0.000000       0.000000        0.000000          0.000000   \n",
       "25%        0.000000       0.000000        0.000000          0.000000   \n",
       "50%        0.000000       0.000000        0.000000          0.000000   \n",
       "75%        0.000000       0.380000        0.000000          0.000000   \n",
       "max       42.810000      10.000000        5.880000          7.270000   \n",
       "\n",
       "       word_freq_internet  word_freq_order     ...       char_freq_;  \\\n",
       "count         4601.000000      4601.000000     ...       4601.000000   \n",
       "mean             0.105295         0.090067     ...          0.038575   \n",
       "std              0.401071         0.278616     ...          0.243471   \n",
       "min              0.000000         0.000000     ...          0.000000   \n",
       "25%              0.000000         0.000000     ...          0.000000   \n",
       "50%              0.000000         0.000000     ...          0.000000   \n",
       "75%              0.000000         0.000000     ...          0.000000   \n",
       "max             11.110000         5.260000     ...          4.385000   \n",
       "\n",
       "       char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.139030     0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.270355     0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.065000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.188000     0.000000     0.315000     0.052000     0.000000   \n",
       "max       9.752000     4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total         spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/spambase.data', sep=',')\n",
    "df = df.reset_index().rename(columns={'index': 'id'})\n",
    "df.info()\n",
    "display(df.head())\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the scatter_matrix functionality\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# define colors list, to be used to plot survived either red (=0) or green (=1)\n",
    "colors=['red','green']\n",
    "\n",
    "# make a scatter plot\n",
    "#scatter_matrix(df,figsize=[20,20],marker='o',c=df.spam.apply(lambda x:colors[x]))\n",
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 4140\n",
      "Test dataset size: 461\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.90\n",
    "test_len = np.int(df.shape[0]*split_ratio)\n",
    "train_len = df.shape[0] - test_len\n",
    "df_train = df.sample(test_len)\n",
    "print 'Training dataset size: %d' % df_train.shape[0]\n",
    "df_test = df.sample(train_len)\n",
    "print 'Test dataset size: %d' % df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize data\n",
    "\n",
    "1.Separate Data By Class\n",
    "\n",
    "2.Calculate Probabilities for multinomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.182069</td>\n",
       "      <td>1.597437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.096317</td>\n",
       "      <td>1.034542</td>\n",
       "      <td>4.616976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_freq_make word_freq_address word_freq_all word_freq_3d  \\\n",
       "               mean              mean          mean         mean   \n",
       "spam                                                               \n",
       "0          0.000724          0.002380      0.001961     0.000010   \n",
       "1          0.001523          0.001649      0.004004     0.001818   \n",
       "\n",
       "     word_freq_our word_freq_over word_freq_remove word_freq_internet  \\\n",
       "              mean           mean             mean               mean   \n",
       "spam                                                                    \n",
       "0         0.001814       0.000451         0.000095           0.000392   \n",
       "1         0.005094       0.001766         0.002674           0.002097   \n",
       "\n",
       "     word_freq_order word_freq_mail           ...             \\\n",
       "                mean           mean           ...              \n",
       "spam                                          ...              \n",
       "0            0.00039       0.001709           ...              \n",
       "1            0.00168       0.003467           ...              \n",
       "\n",
       "     word_freq_conference char_freq_; char_freq_( char_freq_[ char_freq_!  \\\n",
       "                     mean        mean        mean        mean        mean   \n",
       "spam                                                                        \n",
       "0                0.000479    0.000510    0.001587    0.000234    0.001009   \n",
       "1                0.000020    0.000211    0.001104    0.000077    0.005202   \n",
       "\n",
       "     char_freq_$ char_freq_# capital_run_length_average  \\\n",
       "            mean        mean                       mean   \n",
       "spam                                                      \n",
       "0       0.000111    0.000233                   0.023848   \n",
       "1       0.001744    0.000799                   0.096317   \n",
       "\n",
       "     capital_run_length_longest capital_run_length_total  \n",
       "                           mean                     mean  \n",
       "spam                                                      \n",
       "0                      0.182069                 1.597437  \n",
       "1                      1.034542                 4.616976  \n",
       "\n",
       "[2 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean(x):\n",
    "    return np.mean(x/100)\n",
    "\n",
    "df_summary = df_train.drop('id', axis=1).groupby('spam').agg([mean])\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction\n",
    "\n",
    "We are now ready to make predictions using the summaries prepared from our training data. Making predictions involves calculating the probability that a given data instance belongs to each class, then selecting the class with the largest probability as the prediction.\n",
    "\n",
    "We can divide this part into the following tasks:\n",
    "\n",
    "1.Calculate Multinomial Probability Mass Function\n",
    "\n",
    "2.Calculate Class Probabilities\n",
    "\n",
    "3.Make a Prediction\n",
    "\n",
    "4.Estimate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam</th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_re</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>4332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>4054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>3195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.295</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  spam  word_freq_make  word_freq_address  word_freq_all  \\\n",
       "4332  4332     0            0.26                0.0           0.26   \n",
       "4054  4054     0            0.00                0.0           0.00   \n",
       "3195  3195     0            0.00                0.0           0.00   \n",
       "2598  2598     0            0.00                0.0           0.00   \n",
       "1588  1588     1            0.52                0.0           1.05   \n",
       "\n",
       "      word_freq_3d  word_freq_our  word_freq_over  word_freq_remove  \\\n",
       "4332           0.0           0.52            0.00               0.0   \n",
       "4054           0.0           0.00            0.00               0.0   \n",
       "3195           0.0           0.00            0.00               0.0   \n",
       "2598           0.0           0.00            0.00               0.0   \n",
       "1588           0.0           0.00            1.05               0.0   \n",
       "\n",
       "      word_freq_internet     ...       word_freq_re  word_freq_edu  \\\n",
       "4332                 0.0     ...               0.00           0.00   \n",
       "4054                 0.0     ...               0.00           1.07   \n",
       "3195                 0.0     ...               0.58           0.00   \n",
       "2598                 0.0     ...               0.61           0.00   \n",
       "1588                 0.0     ...               0.00           0.00   \n",
       "\n",
       "      word_freq_table  word_freq_conference  char_freq_;  char_freq_(  \\\n",
       "4332              0.0                   0.0        0.000        0.000   \n",
       "4054              0.0                   0.0        0.000        0.197   \n",
       "3195              0.0                   0.0        0.000        0.107   \n",
       "2598              0.0                   0.0        0.095        0.380   \n",
       "1588              0.0                   0.0        0.000        0.000   \n",
       "\n",
       "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \n",
       "4332         0.00        0.038        0.000        0.038  \n",
       "4054         0.00        0.000        0.000        0.000  \n",
       "3195         0.00        0.107        0.000        0.000  \n",
       "2598         0.19        0.190        0.000        0.000  \n",
       "1588         0.00        2.295        0.698        0.000  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4332</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4054</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3195</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2598</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  spam        variable  value\n",
       "0  4332     0  word_freq_make   0.26\n",
       "1  4054     0  word_freq_make   0.00\n",
       "2  3195     0  word_freq_make   0.00\n",
       "3  2598     0  word_freq_make   0.00\n",
       "4  1588     1  word_freq_make   0.52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>measures</th>\n",
       "      <th>spam</th>\n",
       "      <th>variable</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>0.023848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>0.182069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>capital_run_length_total</td>\n",
       "      <td>1.597437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>char_freq_!</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>char_freq_#</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "measures  spam                    variable      mean\n",
       "0            0  capital_run_length_average  0.023848\n",
       "1            0  capital_run_length_longest  0.182069\n",
       "2            0    capital_run_length_total  1.597437\n",
       "3            0                 char_freq_!  0.001009\n",
       "4            0                 char_freq_#  0.000233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam_x</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>spam_y</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4332</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4332</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4054</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3195</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  spam_x        variable  value  spam_y      mean\n",
       "0  4332       0  word_freq_make   0.26       0  0.000724\n",
       "1  4332       0  word_freq_make   0.26       1  0.001523\n",
       "2  4054       0  word_freq_make   0.00       0  0.000724\n",
       "3  4054       0  word_freq_make   0.00       1  0.001523\n",
       "4  3195       0  word_freq_make   0.00       0  0.000724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_cols = df_summary.stack().columns.tolist()\n",
    "\n",
    "cols = ['id', 'spam'] + df_test.columns[(df_test.columns.str.contains('word_'))  | (df_test.columns.str.contains('char_'))].tolist()\n",
    "df_test_sample = df_test[cols]\n",
    "display(df_test_sample.head())\n",
    "df_test_sample = pd.melt(df_test_sample, id_vars=['id', 'spam'], value_vars=var_cols)\n",
    "display(df_test_sample.head())\n",
    "\n",
    "df_aux = df_summary.stack().reset_index()\n",
    "df_aux.rename(columns={'level_1':'measures'}, inplace=True)\n",
    "df_metled_summary = pd.melt(df_aux, id_vars=['spam', 'measures'], value_vars=var_cols)\n",
    "df_metled_summary = df_metled_summary.pivot_table(values='value', index=['spam', 'variable'], columns=['measures'])\n",
    "df_metled_summary = df_metled_summary.reset_index()\n",
    "display(df_metled_summary.head())\n",
    "\n",
    "df_test_sample = df_test_sample.merge(df_metled_summary, on=['variable'], how='left')\n",
    "display(df_test_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52554 entries, 0 to 52553\n",
      "Data columns (total 6 columns):\n",
      "id          52554 non-null int64\n",
      "spam_x      52554 non-null int64\n",
      "variable    52554 non-null object\n",
      "value       49788 non-null float64\n",
      "spam_y      52554 non-null int64\n",
      "mean        52554 non-null float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam probability: 0.39\n",
      "Not Spam probability: 0.61\n"
     ]
    }
   ],
   "source": [
    "spam_prob = {0: df[df.spam == 0].shape[0]/np.float(df.shape[0]),\n",
    "             1: df[df.spam == 1].shape[0]/np.float(df.shape[0])}\n",
    "print 'Spam probability: %.2f' % spam_prob[1] \n",
    "print 'Not Spam probability: %.2f' % spam_prob[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam_x</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>spam_y</th>\n",
       "      <th>mean</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4332</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>-10.646883</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4332</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>-9.661821</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4054</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>-21.399211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4054</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>-27.546315</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3195</td>\n",
       "      <td>0</td>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>-10.994313</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  spam_x        variable  value  spam_y      mean   log_prob  prob\n",
       "0  4332       0  word_freq_make   0.26       0  0.000724 -10.646883   0.0\n",
       "1  4332       0  word_freq_make   0.26       1  0.001523  -9.661821   0.0\n",
       "2  4054       0  word_freq_make   0.00       0  0.000724 -21.399211   0.0\n",
       "3  4054       0  word_freq_make   0.00       1  0.001523 -27.546315   0.0\n",
       "4  3195       0  word_freq_make   0.00       0  0.000724 -10.994313   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "#df_test_sample['odds'] = df_test_sample.groupby(['id'])['log_prob'].transform(sum)\n",
    "#display(df_test_sample.head())\n",
    "#df_test_sample['odds'] = df_test_sample['log_prob']/df_test_sample['odds']\n",
    "#display(df_test_sample.head())\n",
    "\n",
    "def foo(df):\n",
    "    #pdb.set_trace()\n",
    "    df['log_prob'] = np.log10(spam_prob[df.spam_x.max()]) + (df['value']*np.log10(df['mean'])).sum()\n",
    "    df['prob'] = (spam_prob[df.spam_x.max()])*((df['value']*(df['mean'])).product())\n",
    "    return df\n",
    "\n",
    "df_test_sample = df_test_sample.groupby(['id', 'spam_x', 'spam_y']).apply(foo)\n",
    "display(df_test_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam_x</th>\n",
       "      <th>spam_y</th>\n",
       "      <th>log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-31.922324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-26.667379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.733650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.022204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.629386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  spam_x  spam_y   log_prob\n",
       "0   1       1       0 -31.922324\n",
       "1   1       1       1 -26.667379\n",
       "2   9       1       0 -16.733650\n",
       "3   9       1       1 -14.022204\n",
       "4  20       1       0  -4.629386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spam_x</th>\n",
       "      <th>spam_y</th>\n",
       "      <th>log_prob</th>\n",
       "      <th>right_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-26.667379</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.022204</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.225109</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.994399</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.348003</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  spam_x  spam_y   log_prob right_prediction\n",
       "1   1       1       1 -26.667379             True\n",
       "3   9       1       1 -14.022204             True\n",
       "5  20       1       1  -4.225109             True\n",
       "7  23       1       1 -16.994399             True\n",
       "8  24       1       0  -6.348003            False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_sample = df_test_sample.groupby([\n",
    "        'id', 'spam_x', 'spam_y'], as_index=False)[['log_prob']].max()\n",
    "display(df_test_sample.head())\n",
    "\n",
    "###############\n",
    "#df_test_sample['odds'] = df_test_sample.groupby(['id'])['log_prob'].transform(sum)\n",
    "#display(df_test_sample.head())\n",
    "#df_test_sample['odds'] = df_test_sample['log_prob']/df_test_sample['odds']\n",
    "#display(df_test_sample.head())\n",
    "###############\n",
    "\n",
    "idx = (df_test_sample.groupby(['id', 'spam_x'])['log_prob'].transform(max) == df_test_sample['log_prob'])\n",
    "df_test_sample = df_test_sample[idx]\n",
    "df_test_sample['right_prediction'] = (df_test_sample.spam_x - df_test_sample.spam_y == 0)\n",
    "display(df_test_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_prediction</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id\n",
       "right_prediction     \n",
       "False              73\n",
       "True              403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 84.7%\n"
     ]
    }
   ],
   "source": [
    "df_result = df_test_sample.groupby('right_prediction')[['id']].count()\n",
    "display(df_result)\n",
    "print 'Success rate: %.1f%%' % ((df_result.ix[True]/df_result.sum()).values[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
